# ArxivBuddy

**L'IA qui lit les papiers de recherche pour toi (et te les traduit en humain)**

## ğŸ¯ Use Case

Tu tapes une question genre :

```bash
python arxivSimpler.py "Quels sont les derniers rÃ©sultats sur l'utilisation des transformers pour la biologie computationnelle ?"
```

Et il te rÃ©pond :
- avec 3 Ã  5 papiers rÃ©cents (rÃ©sumÃ©s + liens)
- un rÃ©sumÃ© global vulgarisÃ©
- une synthÃ¨se des approches/solutions
- option : traduction en franÃ§ais / mode "grand public"

## ğŸ›  FonctionnalitÃ©s

- ğŸ” Recherche ArXiv par mots-clÃ©s + filtres (date, domaine, etc.)
- ğŸ“„ RÃ©cupÃ©ration des abstracts / intro / conclusion
- ğŸ§  Vulgarisation auto via LLM
- ğŸ§ª SynthÃ¨se comparative des papiers
- ğŸ—£ Traduction auto (optionnelle)
- ğŸ“ Liens directs vers les PDFs
- ğŸ’¬ Mode chat pour poser plusieurs questions dans un mÃªme fil

## ğŸ¤– Agents

ArxivBuddy utilise une architecture modulaire basÃ©e sur CrewAI :

- **QueryParser** : extrait les bons mots-clÃ©s et domaines
- **ArxivSearcher** : utilise l'API ArXiv pour trouver les bons papiers
- **PaperSummarizer** : lit les abstracts et simplifie
- **Synthesizer** : fusionne les infos, extrait les tendances/mÃ©thodes
- **Translator** (option) : traduit ou adapte selon le niveau souhaitÃ©

## ğŸ’» Installation

```bash
# CrÃ©er un environnement virtuel
python -m venv venv

# Activer l'environnement
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configuration
# Copier le fichier d'exemple et ajoutez vos clÃ©s API
cp config/.env.example config/.env
# Modifier le fichier .env avec votre Ã©diteur prÃ©fÃ©rÃ© pour ajouter votre clÃ© API

# Le fichier .env doit contenir les informations suivantes :
# CREW_API_KEY=sk-or-v1-votre-clÃ©-openrouter-ici
# CREW_MODEL=openai/gpt-4.1-mini
# CREW_TEMPERATURE=0.7
# CREW_MAX_TOKENS=4000
# CREW_BASE_URL=https://openrouter.ai/api/v1
# 
# ARXIV_MAX_RESULTS=5
# ARXIV_SORT_BY=submittedDate
# ARXIV_SORT_ORDER=descending
#
# Vous pouvez obtenir une clÃ© API OpenRouter en vous inscrivant sur https://openrouter.ai
```

## ğŸš€ Utilisation

```bash
# Utilisation simple
python arxivSimpler.py "Quels sont les usages rÃ©cents des transformers en biologie computationnelle ?"

# Avec options
python arxivSimpler.py "Quels sont les usages rÃ©cents des transformers en biologie computationnelle ?" --french --level beginner
```

## Options

```
usage: arxivSimpler.py [-h] [--max-results MAX_RESULTS] [--french] [--level {expert,medium,beginner}] [query]

ArxivBuddy - L'IA qui lit les papiers de recherche pour toi

positional arguments:
  query                 Votre question de recherche

options:
  -h, --help            show this help message and exit
  --max-results MAX_RESULTS
                        Nombre maximum de papiers Ã  rÃ©cupÃ©rer
  --french              Traduire les rÃ©sultats en franÃ§ais
  --level {expert,medium,beginner}
                        Niveau de simplification (expert, medium, beginner)
```

## ğŸ“ Exemple de rÃ©sultat

```markdown
### RÃ©sultat de votre question :
*Quels sont les usages rÃ©cents des transformers en biologie computationnelle ?*

---

#### ğŸ§¬ RÃ©sumÃ© simplifiÃ© :
Les transformers sont utilisÃ©s pour :
- prÃ©dire les structures de protÃ©ines (ex: AlphaFold-like)
- modÃ©liser des sÃ©quences gÃ©nomiques comme des phrases
- amÃ©liorer l'analyse de donnÃ©es single-cell RNA-seq

---

#### ğŸ“š Papiers recommandÃ©s :

1. **"Transformer-based protein structure prediction"**  
   *arxiv.org/abs/2303.xxxxx*  
   â†’ PrÃ©sente un modÃ¨le inspirÃ© de GPT pour la 3D des protÃ©ines.

2. **"Genomic BERT: Pretraining on DNA sequences"**  
   *arxiv.org/abs/2401.xxxxx*  
   â†’ Fine-tuning de BERT pour classifier des sÃ©quences ADN.

3. **"Multi-omics data integration using transformers"**  
   *arxiv.org/abs/2312.xxxxx*  
   â†’ Approche multi-vues pour donnÃ©es biologiques complexes.

---

#### ğŸ” SynthÃ¨se :
Les transformers permettent de mieux apprendre les patterns dans l'ADN et ARN. La tendance va vers des modÃ¨les prÃ©-entraÃ®nÃ©s sur de larges bases biologiques, souvent adaptÃ©s du NLP.
```
